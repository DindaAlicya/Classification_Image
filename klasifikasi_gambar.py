# -*- coding: utf-8 -*-
"""Salinan dari Template Submission Akhir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NiCRh5bUb3PnCTyXgRmdrT2upBt2Q_8F

# Proyek Klasifikasi Gambar: Indonesian Rupiah Currency
- **Nama:** Dinda Alicya Ruiz
- **Email:** alicyaruiz1902@gmail.com
- **ID Dicoding:** dlicyaa
- **Student ID:** MS004D5X0492 (CodingCamp Powered by DBS Foundation)

## Import Semua Packages/Library yang Digunakan
"""

!pip install tensorflow

from google.colab import drive
import os
import shutil
import tensorflow as tf
import numpy as np
import pandas as pd
import seaborn as sns
import cv2
import random
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from keras.models import Sequential
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Mengabaikan peringatan
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

"""## Data Preparation

### Data Loading
"""

# Mount Google Drive
drive.mount('/content/drive')

data_rupiah = '/content/drive/MyDrive/Colab Notebooks/klasifikasi_gambar/rupiah'
base_dir = '/content/drive/My Drive/Colab Notebooks/klasifikasi_gambar/split_dir'

# menghitung jumlah gambar pada dataset

total_images = 0
number_label = {}
for folder in os.listdir(data_rupiah):
    folder_path = os.path.join(data_rupiah, folder)
    if os.path.isdir(folder_path):
        jumlah_gambar = len(os.listdir(folder_path))
        number_label[folder] = jumlah_gambar
        total_images += jumlah_gambar
        print(f"Jumlah gambar {folder}: {jumlah_gambar}")
print(f"\nTotal semua gambar pada dataset: {total_images}")

# distribusi jumlah gambar pada setiap kelas
import matplotlib.pyplot as plt
plt.figure(figsize=(10,5))
plt.bar(number_label.keys(), number_label.values())
plt.title("Jumlah Gambar Tiap Label")
plt.xlabel('Label')
plt.ylabel('Jumlah Gambar')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

sample_paths = []
for class_name in os.listdir(data_rupiah):
    class_path = os.path.join(data_rupiah, class_name)
    if os.path.isdir(class_path):
        images = os.listdir(class_path)
        sample_images = random.sample(images, min(2, len(images)))  # ambil max 2 gambar per kelas
        for img_name in sample_images:
            sample_paths.append(os.path.join(class_path, img_name))

# tampilkan sample gambar dan resolusi aslinya
plt.figure(figsize=(15, 8))
for i, img_path in enumerate(sample_paths[:10]):  # batasi 10 gambar agar tidak kepanjangan
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    h, w, c = img.shape

    plt.subplot(2, 5, i+1)
    plt.imshow(img)
    plt.title(f"{os.path.basename(img_path)}\n{w}x{h}", rotation=25, fontsize=9)
    plt.axis('off')
plt.tight_layout()
plt.show()

"""### Data Preprocessing

#### Split Dataset
"""

#split dataset menjadi 3 bagian (train, validation, dan test)

for split in ['train', 'val', 'test']:
    for class_name in os.listdir(data_rupiah):
        split_dir = os.path.join(base_dir, split, class_name) # split dataset disimpan ke directory base_dir
        os.makedirs(split_dir, exist_ok=True)

# mulai splitting data

for class_name in os.listdir(data_rupiah):
    class_dir = os.path.join(data_rupiah, class_name)
    images = os.listdir(class_dir)

    train_files, temp_files = train_test_split(images, test_size=0.3, random_state=42)
    val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)

    for file_list, split in zip([train_files, val_files, test_files], ['train', 'val', 'test']):
        for filename in file_list:
            src = os.path.join(class_dir, filename)
            dst = os.path.join(base_dir, split, class_name, filename)
            shutil.copy2(src, dst)

train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')
test_dir = os.path.join(base_dir, 'test')

"""dengan ini dataset sudah di split dengan bagian training data 70%, testing data 15% dan validation data 15%.

splitting data berada pada directory "split_dir"

### Rescale dan DataLoading
"""

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

class_names = list(train_generator.class_indices.keys())
print(class_names)

"""## Modelling"""

# membangun model sequential

model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(train_generator.num_classes, activation='softmax')
])

model.summary()

#menambahkan optimizer
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# menambahkan fitur callback (training berhenti ketika sudah mencapai 95%)
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.95 and logs.get('val_accuracy')>0.95):
      print("akurasi model sudah mencapai 95%")
      self.model.stop_training = True

callbacks = myCallback()

num_epochs = 50
history = model.fit(
      train_generator,
      epochs=num_epochs,
      validation_data=val_generator,
      validation_steps=5,
      verbose=2,
      callbacks=[callbacks])

"""## Evaluasi dan Visualisasi

### Menampilkan plot Accuracy
"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title("Accuracy Model")
plt.xlabel("Accuracy")
plt.ylabel('Epoch')
plt.legend(['Train', 'Validation'],loc='lower right')
plt.show()

"""### Menampilkan plot Loss"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Training','Validation' ],loc='upper right')
plt.show()

# prediction test label
Y_pred = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size+1)
y_pred = np.argmax(Y_pred, axis=1)

# actual test label
y_true = test_generator.classes

# Laporan klasifikasi
print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))

test_loss, test_acc = model.evaluate(test_generator, steps=5, verbose=1)
print(f"Akurasi pada test set: {test_acc * 100:.2f}%")

# Test modell

image_path = '/content/drive/MyDrive/Colab Notebooks/klasifikasi_gambar/rupiah/10000/IMG20210327135101.jpg'

# Load & proses gambar
img = image.load_img(image_path, target_size=(224, 224))
plt.imshow(img)
plt.axis('off')
plt.show()

x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x /= 255.0

# Prediksi
prediction = model.predict(x)


predicted_class_index = np.argmax(prediction)
class_labels = list(train_generator.class_indices.keys())
predicted_label = class_labels[predicted_class_index]

print(f"Prediksi: {predicted_label}")

"""## Konversi Model"""

# simpan model dalam format SavedModel, TFLite dan TFJS
export_dir = '/content/drive/My Drive/Colab Notebooks/klasifikasi_gambar/exported_model'
saved_model_dir = os.path.join(export_dir, 'saved_model')
tflite_model_path = os.path.join(export_dir, 'model.tflite')
tfjs_model_dir = os.path.join(export_dir, 'tfjs_model')

os.makedirs(export_dir, exist_ok=True)

model.export(saved_model_dir)
print(f"berhasil simpan model dalam format SavedModel")

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()

with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)
print(f"berhasil simpan model dalam format TFLite")

!pip install tensorflowjs

!cp -r "/content/drive/My Drive/Colab Notebooks/klasifikasi_gambar/exported_model/saved_model" /content/


!tensorflowjs_converter \
  --input_format=tf_saved_model \
  --output_format=tfjs_graph_model \
  "/content/saved_model" \
  "/content/tfjs_model"


from google.colab import files
import os

for f in os.listdir("/content/tfjs_model"):
    files.download(f"/content/tfjs_model/{f}")

"""## Inference (Optional)"""

